"""
LLM å¤„ç†æ¨¡å—ï¼šè°ƒç”¨å¤§è¯­è¨€æ¨¡å‹ API
"""
import requests
from typing import Optional, Tuple, List, Dict

from .config import PodcastConfig
from .parser import smart_parse_script


def call_llm_step(
    config: PodcastConfig,
    prompt: str,
    content: str,
    step_name: str = "LLM",
    temperature: float = 0.7,
    max_tokens: int = 2048
) -> Optional[str]:
    """
    è°ƒç”¨ LLM API
    
    Args:
        config: é…ç½®å¯¹è±¡
        prompt: ç³»ç»Ÿæç¤ºè¯
        content: ç”¨æˆ·è¾“å…¥å†…å®¹
        step_name: æ­¥éª¤åç§°ï¼ˆç”¨äºæ—¥å¿—ï¼‰
        temperature: ç”Ÿæˆæ¸©åº¦
        max_tokens: æœ€å¤§ token æ•°
        
    Returns:
        LLM è¿”å›çš„å†…å®¹ï¼Œå¤±è´¥è¿”å› None
    """
    url = "https://api.siliconflow.cn/v1/chat/completions"
    headers = {
        "Authorization": f"Bearer {config.api_key}",
        "Content-Type": "application/json"
    }
    
    payload = {
        "model": config.llm_model_name,
        "messages": [
            {"role": "system", "content": prompt},
            {"role": "user", "content": content}
        ],
        "temperature": temperature,
        "max_tokens": max_tokens
    }
    
    print(f"      ğŸ“¤ [{step_name}] è°ƒç”¨æ¨¡å‹: {config.llm_model_name}")
    print(f"      ğŸ“¤ [{step_name}] è¾“å…¥é•¿åº¦: {len(content)} å­—ç¬¦")
    
    try:
        response = requests.post(url, json=payload, headers=headers, timeout=120)
        
        print(f"      ğŸ“¥ [{step_name}] HTTP Status: {response.status_code}")
        
        if response.status_code == 200:
            result = response.json()
            if 'choices' in result and len(result['choices']) > 0:
                output = result['choices'][0]['message']['content']
                print(f"      âœ… [{step_name}] æˆåŠŸï¼Œè¾“å‡ºé•¿åº¦: {len(output)} å­—ç¬¦")
                
                # æ˜¾ç¤º token ä½¿ç”¨æƒ…å†µ
                if 'usage' in result:
                    usage = result['usage']
                    print(f"      ğŸ“Š [{step_name}] Tokens: prompt={usage.get('prompt_tokens', '?')}, completion={usage.get('completion_tokens', '?')}, total={usage.get('total_tokens', '?')}")
                
                return output
            else:
                print(f"      âŒ [{step_name}] å“åº”æ ¼å¼å¼‚å¸¸: {result}")
                return None
        else:
            print(f"      âŒ [{step_name}] API é”™è¯¯:")
            print(f"         Status: {response.status_code}")
            print(f"         Response: {response.text[:500]}")
            return None
            
    except requests.exceptions.Timeout:
        print(f"      âŒ [{step_name}] è¯·æ±‚è¶…æ—¶ (120s)")
        return None
    except Exception as e:
        print(f"      âŒ [{step_name}] Exception: {type(e).__name__}: {e}")
        return None


def process_article(
    config: PodcastConfig,
    index: int,
    url: str,
    raw_text: str
) -> Tuple[int, str, Optional[str], Optional[List[Dict[str, str]]]]:
    """
    å¤„ç†å•ç¯‡æ–‡ç« ï¼šåˆ†æ + ç”Ÿæˆè„šæœ¬
    
    Args:
        config: é…ç½®å¯¹è±¡
        index: æ–‡ç« ç´¢å¼•
        url: æ–‡ç«  URL
        raw_text: æ–‡ç« åŸå§‹å†…å®¹
        
    Returns:
        (index, url, readable_script, script_json) å…ƒç»„
    """
    if not raw_text:
        print(f"ğŸ§  [Task {index+1}] âŒ è¾“å…¥å†…å®¹ä¸ºç©º")
        return index, url, None, None

    prompts = config.get_prompts()
    
    print(f"ğŸ§  [Task {index+1}] å¼€å§‹å¤„ç†: {url[:60]}...")
    print(f"   ğŸ“„ åŸæ–‡é•¿åº¦: {len(raw_text)} å­—ç¬¦ (æˆªå–å‰ 10000)")
    
    # ç¬¬ä¸€æ­¥ï¼šåˆ†ææ–‡ç« 
    print(f"   ğŸ” Step 1: æ–‡ç« åˆ†æ...")
    analysis = call_llm_step(
        config,
        prompts["analyst"],
        raw_text[:10000],
        step_name="Analyst"
    )
    
    if not analysis:
        print(f"ğŸ§  [Task {index+1}] âŒ æ–‡ç« åˆ†æå¤±è´¥")
        return index, url, None, None
    
    # ç¬¬äºŒæ­¥ï¼šç”Ÿæˆè„šæœ¬
    print(f"   âœï¸ Step 2: ç”Ÿæˆè„šæœ¬...")
    script_raw = call_llm_step(
        config,
        prompts["playwright"],
        f"ã€ç®€æŠ¥ã€‘ï¼š\n{analysis}",
        step_name="Playwright"
    )
    
    if not script_raw:
        print(f"ğŸ§  [Task {index+1}] âŒ è„šæœ¬ç”Ÿæˆå¤±è´¥")
        return index, url, None, None
    
    # è§£æè„šæœ¬
    print(f"   ğŸ”§ Step 3: è§£æè„šæœ¬ JSON...")
    script_json = smart_parse_script(script_raw)
    
    if not script_json:
        print(f"ğŸ§  [Task {index+1}] âŒ è„šæœ¬è§£æå¤±è´¥")
        print(f"{'!'*50}")
        print(f"ğŸ“œ åŸå§‹è¿”å› (å‰ 800 å­—ç¬¦):")
        print(script_raw[:800] if script_raw else 'None')
        print(f"{'!'*50}")
        return index, url, None, None
    
    # ç”Ÿæˆå¯è¯»æ–‡æœ¬
    readable_script = f"Source: {url}\n\n"
    for line in script_json:
        spk = line['speaker']
        txt = line['text']
        readable_script += f"{spk}: {txt}\n"
    readable_script += "\n" + "="*20 + "\n\n"
    
    print(f"ğŸ§  [Task {index+1}] âœ… å¤„ç†å®Œæˆï¼Œç”Ÿæˆ {len(script_json)} è¡Œå¯¹è¯")
    return index, url, readable_script, script_json
