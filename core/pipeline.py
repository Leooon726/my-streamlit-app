"""
ä¸»æµç¨‹æ¨¡å—ï¼šåè°ƒå„æ¨¡å—å®Œæˆæ’­å®¢ç”Ÿæˆ

æ¶æ„ï¼š
- Stage 1: Jina æŠ“å– (å¹¶è¡Œ)
- Stage 2: LLM åˆ†æ (å¹¶è¡Œ)
- Stage 3: LLM ç»Ÿä¸€æ’°å†™è„šæœ¬ (ä¸²è¡Œ)
- Stage 4: TTS ç”ŸæˆéŸ³é¢‘ (å¹¶è¡Œ)
- Stage 5: éŸ³é¢‘åˆå¹¶ (ä¸²è¡Œ)
"""
import io
from typing import Optional, Callable, List, Dict, Any, Tuple
from concurrent.futures import ThreadPoolExecutor, as_completed
from dataclasses import dataclass

from pydub import AudioSegment

from .config import PodcastConfig
from .fetcher import fetch_content_with_jina
from .llm import analyze_article, generate_unified_script
from .audio import generate_audio_parallel, merge_audio_segments


@dataclass
class PipelineResult:
    """æµç¨‹æ‰§è¡Œç»“æœ"""
    success: bool
    title: str = ""
    script_text: str = ""
    audio_data: Optional[bytes] = None
    error_message: str = ""
    stats: Dict[str, Any] = None
    
    def __post_init__(self):
        if self.stats is None:
            self.stats = {}


class PodcastPipeline:
    """æ’­å®¢ç”Ÿæˆæµæ°´çº¿"""
    
    def __init__(self, config: PodcastConfig):
        self.config = config
        self.log_callback: Optional[Callable[[str], None]] = None
        self.progress_callback: Optional[Callable[[str, float], None]] = None
        
    def set_log_callback(self, callback: Callable[[str], None]):
        """è®¾ç½®æ—¥å¿—å›è°ƒ"""
        self.log_callback = callback
        
    def set_progress_callback(self, callback: Callable[[str, float], None]):
        """è®¾ç½®è¿›åº¦å›è°ƒ (stage, progress)"""
        self.progress_callback = callback
        
    def log(self, message: str):
        """è®°å½•æ—¥å¿—"""
        print(message)
        if self.log_callback:
            self.log_callback(message)
            
    def update_progress(self, stage: str, progress: float):
        """æ›´æ–°è¿›åº¦"""
        if self.progress_callback:
            self.progress_callback(stage, progress)
    
    def run(self) -> PipelineResult:
        """
        æ‰§è¡Œå®Œæ•´çš„æ’­å®¢ç”Ÿæˆæµç¨‹
        """
        # éªŒè¯é…ç½®
        valid, error = self.config.validate()
        if not valid:
            return PipelineResult(success=False, error_message=error)
        
        # æ‰“å°é…ç½®ä¿¡æ¯å’Œæ¶æ„è¯´æ˜
        self.log(f"{'='*60}")
        self.log(f"ğŸ™ï¸ AI Podcast Generator")
        self.log(f"{'='*60}")
        self.log(f"")
        self.log(f"ğŸ“‹ é…ç½®ä¿¡æ¯:")
        self.log(f"   æ¨¡å¼: {self.config.podcast_mode}")
        self.log(f"   LLM: {self.config.llm_model_name}")
        self.log(f"   TTS: {self.config.tts_model_name}")
        self.log(f"   éŸ³è‰² A: {self.config.voice_a_full}")
        self.log(f"   éŸ³è‰² B: {self.config.voice_b_full}")
        self.log(f"   éŸ³é¢‘ç”Ÿæˆ: {'å¯ç”¨' if self.config.enable_audio_generation else 'ç¦ç”¨'}")
        self.log(f"")
        self.log(f"ğŸ—ï¸ å¤„ç†æ¶æ„:")
        self.log(f"   Stage 1: Jina æŠ“å–    [å¹¶è¡Œ x{self.config.max_workers_jina}]")
        self.log(f"   Stage 2: LLM åˆ†æ     [å¹¶è¡Œ x{self.config.max_workers_llm}]")
        self.log(f"   Stage 3: ç»Ÿä¸€æ’°å†™è„šæœ¬ [ä¸²è¡Œ - ä¿è¯è¿è´¯æ€§]")
        self.log(f"   Stage 4: TTS ç”Ÿæˆ     [å¹¶è¡Œ x{self.config.max_workers_tts}]")
        self.log(f"   Stage 5: éŸ³é¢‘åˆå¹¶     [ä¸²è¡Œ - æŒ‰é¡ºåºæ‹¼æ¥]")
        self.log(f"{'='*60}")
            
        urls = self.config.urls
        stats = {
            "total_urls": len(urls),
            "fetched": 0,
            "analyzed": 0,
            "script_lines": 0,
            "audio_segments": 0,
        }
        
        # ==========================================
        # Stage 1: Jina Fetching (å¹¶è¡Œ)
        # ==========================================
        self.log(f"")
        self.log(f"{'='*60}")
        self.log(f"ğŸš€ STAGE 1: Jina æŠ“å– [å¹¶è¡Œ x{self.config.max_workers_jina}]")
        self.log(f"{'='*60}")
        self.log(f"   URLs ({len(urls)}):")
        for i, url in enumerate(urls):
            self.log(f"      [{i+1}] {url}")
        self.log(f"")
        
        self.update_progress("fetching", 0.0)
        
        fetched_data = []  # [(index, url, content), ...]
        
        with ThreadPoolExecutor(max_workers=self.config.max_workers_jina) as executor:
            futures = {}
            for i, url in enumerate(urls):
                future = executor.submit(
                    self._fetch_task, i, url
                )
                futures[future] = i
            
            for future in as_completed(futures):
                idx, url, content = future.result()
                self.update_progress("fetching", len(fetched_data) / len(urls))
                
                if content:
                    fetched_data.append((idx, url, content))
                    stats["fetched"] += 1
                    self.log(f"   âœ… [{idx+1}] æˆåŠŸ: {len(content)} å­—ç¬¦")
                else:
                    self.log(f"   âŒ [{idx+1}] å¤±è´¥: {url[:50]}...")
        
        self.update_progress("fetching", 1.0)
        self.log(f"")
        self.log(f"ğŸ“Š Stage 1 å®Œæˆ: {stats['fetched']}/{len(urls)} æˆåŠŸ")
                    
        if not fetched_data:
            self.log(f"âŒ æ‰€æœ‰é“¾æ¥æŠ“å–å¤±è´¥")
            return PipelineResult(
                success=False,
                error_message="æ‰€æœ‰é“¾æ¥æŠ“å–å¤±è´¥",
                stats=stats
            )
            
        # ==========================================
        # Stage 2: LLM åˆ†æ (å¹¶è¡Œ)
        # ==========================================
        self.log(f"")
        self.log(f"{'='*60}")
        self.log(f"ğŸš€ STAGE 2: LLM åˆ†æ [å¹¶è¡Œ x{self.config.max_workers_llm}]")
        self.log(f"{'='*60}")
        self.log(f"   å¾…åˆ†æ: {len(fetched_data)} ç¯‡æ–‡ç« ")
        self.log(f"   æ³¨æ„: å‘é€å…¨æ–‡ï¼Œæ— å­—æ•°æˆªæ–­")
        self.log(f"")
        
        self.update_progress("analyzing", 0.0)
        
        analyses = []  # [(index, url, analysis), ...]
        
        with ThreadPoolExecutor(max_workers=self.config.max_workers_llm) as executor:
            futures = {}
            for idx, url, content in fetched_data:
                future = executor.submit(
                    analyze_article,
                    self.config, idx, url, content, self.log
                )
                futures[future] = idx
            
            completed = 0
            for future in as_completed(futures):
                completed += 1
                self.update_progress("analyzing", completed / len(fetched_data))
                
                idx, url, analysis = future.result()
                if analysis:
                    analyses.append((idx, url, analysis))
                    stats["analyzed"] += 1
        
        self.log(f"")
        self.log(f"ğŸ“Š Stage 2 å®Œæˆ: {stats['analyzed']}/{len(fetched_data)} æˆåŠŸ")
        
        if not analyses:
            self.log(f"âŒ æ‰€æœ‰æ–‡ç« åˆ†æå¤±è´¥")
            return PipelineResult(
                success=False,
                error_message="æ‰€æœ‰æ–‡ç« åˆ†æå¤±è´¥",
                stats=stats
            )
        
        # ==========================================
        # Stage 3: ç»Ÿä¸€æ’°å†™è„šæœ¬ (ä¸²è¡Œ)
        # ==========================================
        self.log(f"")
        self.log(f"{'='*60}")
        self.log(f"ğŸš€ STAGE 3: ç»Ÿä¸€æ’°å†™è„šæœ¬ [ä¸²è¡Œ - ä¿è¯å‰åæ–‡è¿è´¯]")
        self.log(f"{'='*60}")
        
        self.update_progress("writing", 0.0)
        
        # æŒ‰åŸå§‹é¡ºåºæ’åº
        analyses.sort(key=lambda x: x[0])
        
        generated_title, script_json = generate_unified_script(
            self.config,
            analyses,
            self.log
        )
        
        self.update_progress("writing", 1.0)
        
        if not script_json:
            self.log(f"âŒ è„šæœ¬ç”Ÿæˆå¤±è´¥")
            return PipelineResult(
                success=False,
                error_message="è„šæœ¬ç”Ÿæˆå¤±è´¥",
                stats=stats
            )
        
        # ä½¿ç”¨ç”Ÿæˆçš„æ ‡é¢˜ï¼Œå¦‚æœæ²¡æœ‰åˆ™ä½¿ç”¨é»˜è®¤æ ‡é¢˜
        podcast_title = generated_title or f"Podcast {len(urls)} ç¯‡æ–‡ç« "
        
        stats["script_lines"] = len(script_json)
        
        # ç”Ÿæˆå¯è¯»è„šæœ¬æ–‡æœ¬
        script_text = f"=== {podcast_title} ===\n\n"
        for idx, url, _ in analyses:
            script_text += f"Source {idx+1}: {url}\n"
        script_text += "\n" + "="*40 + "\n\n"
        
        for line in script_json:
            script_text += f"{line['speaker']}: {line['text']}\n\n"
        
        self.log(f"")
        self.log(f"ğŸ“Š Stage 3 å®Œæˆ: æ ‡é¢˜ã€Œ{podcast_title}ã€, {len(script_json)} è¡Œå¯¹è¯")
        
        # ==========================================
        # Stage 4 & 5: éŸ³é¢‘ç”Ÿæˆå’Œåˆå¹¶
        # ==========================================
        audio_bytes = None
        
        if self.config.enable_audio_generation:
            # Stage 4: TTS å¹¶è¡Œç”Ÿæˆ
            self.log(f"")
            self.log(f"{'='*60}")
            self.log(f"ğŸš€ STAGE 4: TTS ç”Ÿæˆ [å¹¶è¡Œ x{self.config.max_workers_tts}]")
            self.log(f"{'='*60}")
            
            self.update_progress("tts", 0.0)
            
            audio_segments, audio_errors = generate_audio_parallel(
                self.config,
                script_json,
                self.log
            )
            
            self.update_progress("tts", 1.0)
            
            stats["audio_segments"] = len(audio_segments)
            
            if not audio_segments:
                self.log(f"âŒ æ‰€æœ‰éŸ³é¢‘ç”Ÿæˆå¤±è´¥")
            else:
                # Stage 5: éŸ³é¢‘åˆå¹¶ (ä¸²è¡Œ)
                self.log(f"")
                self.log(f"{'='*60}")
                self.log(f"ğŸš€ STAGE 5: éŸ³é¢‘åˆå¹¶ [ä¸²è¡Œ - æŒ‰é¡ºåºæ‹¼æ¥]")
                self.log(f"{'='*60}")
                
                self.update_progress("merging", 0.0)
                
                final_audio = merge_audio_segments(audio_segments, self.log)
                
                self.update_progress("merging", 1.0)
                
                if len(final_audio) > 0:
                    buffer = io.BytesIO()
                    final_audio.export(buffer, format="mp3")
                    audio_bytes = buffer.getvalue()
                    
                    self.log(f"")
                    self.log(f"ğŸ‰ éŸ³é¢‘å¯¼å‡ºå®Œæˆ!")
                    self.log(f"   æ–‡ä»¶å¤§å°: {len(audio_bytes)/1024:.1f} KB")
                else:
                    self.log(f"âš ï¸ éŸ³é¢‘åˆå¹¶åä¸ºç©º")
        else:
            self.log(f"")
            self.log(f"âšª éŸ³é¢‘ç”Ÿæˆå·²è·³è¿‡ï¼ˆæœªå¯ç”¨ï¼‰")
        
        # ==========================================
        # æœ€ç»ˆæ±‡æ€»
        # ==========================================
        self.log(f"")
        self.log(f"{'='*60}")
        self.log(f"ğŸ“Š æœ€ç»ˆç»Ÿè®¡")
        self.log(f"{'='*60}")
        self.log(f"   é“¾æ¥æ€»æ•°: {stats['total_urls']}")
        self.log(f"   æŠ“å–æˆåŠŸ: {stats['fetched']}")
        self.log(f"   åˆ†ææˆåŠŸ: {stats['analyzed']}")
        self.log(f"   è„šæœ¬è¡Œæ•°: {stats['script_lines']}")
        self.log(f"   éŸ³é¢‘ç‰‡æ®µ: {stats['audio_segments']}")
        self.log(f"{'='*60}")
        self.log(f"âœ… å¤„ç†å®Œæˆ!")
            
        self.update_progress("complete", 1.0)
        
        return PipelineResult(
            success=True,
            title=podcast_title,
            script_text=script_text,
            audio_data=audio_bytes,
            stats=stats
        )
    
    def _fetch_task(self, index: int, url: str) -> Tuple[int, str, Optional[str]]:
        """æŠ“å–ä»»åŠ¡ï¼ˆä¾›å¹¶è¡Œè°ƒç”¨ï¼‰"""
        self.log(f"   ğŸŒ [{index+1}] å¼€å§‹æŠ“å–: {url[:50]}...")
        content = fetch_content_with_jina(url, log_func=self.log)
        return index, url, content
